# L5Driving â€“ Minimalist Autonomous Navigation Logic

This isnâ€™t a full stack.  
This is everything you actually need â€” and nothing else.

---

## ðŸš— What It Is

A simplified Level 5 driving logic system.

No lidar.  
No giant models.  
No hallucinations.

> Just vector physics, dual-camera input, and predictive collisions.

---

## ðŸ§  Core Concepts

- **Dual-camera depth emulation** â€“ calculates range with stereo input  
- **Impact prediction vector model** â€“ determines object threat by vector intersection  
- **Simplified decision tree logic** â€“ no ML, just trajectory math  
- **Failsafe-first behavior loop** â€“ system always prioritizes physical integrity over path loyalty

---

## ðŸ’¸ Why?

Because most L5 systems are overengineered, sensor-heavy, and economically unsustainable.

This model was designed for:

- Edge devices  
- Cheap hardware  
- Reliable fallback navigation  
- AI-optional deployment

---

## ðŸ”§ Components

- `impact_vector_predictor.py`  
- `trajectory_simulator.py`  
- `dualcam_depth_solver.py`

All fully embeddable into low-cost chips.

---

## ðŸ¤· Limitations

- No semantic parsing â€” pedestrians are just velocity+mass vectors  
- No map preloading â€” system is live-context only  
- Best paired with hardware redundancy

---

## ðŸ§ª Status

Prototype logic only.  
Proof-of-concept modules in design.

Funding or co-development welcome.  
Because weâ€™d rather crash softly than drift intelligently.

---

ðŸ“® bramblestudio.sibyl@gmail.com
